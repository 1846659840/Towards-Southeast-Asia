{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXz51el9AhVy"
      },
      "source": [
        "自動化流程"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjbyS_KL_6-6",
        "outputId": "61060a9f-6e36-4ee8-ef0a-33ac752e6e15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "合并后的音频已保存到：/content/combined_audio.wav\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Tgww3Cp7mV-"
      },
      "source": [
        "注意事項：雲端運行請設置如下！\n",
        "根据错误信息和提供的代码，你可以按照以下步骤进行修改：\n",
        "\n",
        "打开audio.py文件。\n",
        "找到_build_mel_basis()函数。\n",
        "修改librosa.filters.mel函数的调用方式，确保所有参数都作为关键字参数传递。\n",
        "\n",
        "return librosa.filters.mel(sr=hp.sample_rate, n_fft=hp.n_fft, n_mels=hp.num_mels, fmin=hp.fmin, fmax=hp.fmax)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngxaqxMdU-T1"
      },
      "source": [
        "自動化流程"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zA3UeiPCsjKg",
        "outputId": "82eb5cf5-11a6-4763-c90c-71f4b13727ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Done\n",
            "Collecting python-pptx\n",
            "  Downloading python_pptx-0.6.23-py3-none-any.whl (471 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-pptx) (4.9.4)\n",
            "Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.10/dist-packages (from python-pptx) (9.4.0)\n",
            "Collecting XlsxWriter>=0.5.7 (from python-pptx)\n",
            "  Downloading XlsxWriter-3.2.0-py3-none-any.whl (159 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.9/159.9 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: XlsxWriter, python-pptx\n",
            "Successfully installed XlsxWriter-3.2.0 python-pptx-0.6.23\n",
            "Thu Apr 25 07:00:06 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n",
            "Cloning into 'Linly-Talker'...\n",
            "remote: Enumerating objects: 1095, done.\u001b[K\n",
            "remote: Counting objects: 100% (377/377), done.\u001b[K\n",
            "remote: Compressing objects: 100% (224/224), done.\u001b[K\n",
            "remote: Total 1095 (delta 170), reused 348 (delta 147), pack-reused 718\u001b[K\n",
            "Receiving objects: 100% (1095/1095), 59.59 MiB | 35.05 MiB/s, done.\n",
            "Resolving deltas: 100% (420/420), done.\n",
            "/content/Linly-Talker\n",
            "Collecting librosa==0.9.2 (from -r VITS/requirements_gptsovits.txt (line 1))\n",
            "  Downloading librosa-0.9.2-py3-none-any.whl (214 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.3/214.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numba==0.56.4 (from -r VITS/requirements_gptsovits.txt (line 2))\n",
            "  Downloading numba-0.56.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytorch-lightning (from -r VITS/requirements_gptsovits.txt (line 3))\n",
            "  Downloading pytorch_lightning-2.2.3-py3-none-any.whl (802 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.2/802.2 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ffmpeg-python in /usr/local/lib/python3.10/dist-packages (from -r VITS/requirements_gptsovits.txt (line 4)) (0.2.0)\n",
            "Collecting onnxruntime (from -r VITS/requirements_gptsovits.txt (line 5))\n",
            "  Downloading onnxruntime-1.17.3-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r VITS/requirements_gptsovits.txt (line 6)) (4.66.2)\n",
            "Collecting funasr>=1.0.0 (from -r VITS/requirements_gptsovits.txt (line 7))\n",
            "  Downloading funasr-1.0.25-py3-none-any.whl (673 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m673.7/673.7 kB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cn2an (from -r VITS/requirements_gptsovits.txt (line 8))\n",
            "  Downloading cn2an-0.5.22-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.0/225.0 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pypinyin (from -r VITS/requirements_gptsovits.txt (line 9))\n",
            "  Downloading pypinyin-0.51.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyopenjtalk (from -r VITS/requirements_gptsovits.txt (line 10))\n",
            "  Downloading pyopenjtalk-0.3.3.tar.gz (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting g2p_en (from -r VITS/requirements_gptsovits.txt (line 11))\n",
            "  Downloading g2p_en-2.1.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting modelscope==1.10.0 (from -r VITS/requirements_gptsovits.txt (line 12))\n",
            "  Downloading modelscope-1.10.0-py3-none-any.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m65.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from -r VITS/requirements_gptsovits.txt (line 13)) (0.1.99)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from -r VITS/requirements_gptsovits.txt (line 14)) (5.2.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from -r VITS/requirements_gptsovits.txt (line 15)) (6.0.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r VITS/requirements_gptsovits.txt (line 16)) (5.9.5)\n",
            "Collecting jieba_fast (from -r VITS/requirements_gptsovits.txt (line 17))\n",
            "  Downloading jieba_fast-0.53.tar.gz (7.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from -r VITS/requirements_gptsovits.txt (line 18)) (0.42.1)\n",
            "Collecting LangSegment (from -r VITS/requirements_gptsovits.txt (line 19))\n",
            "  Downloading LangSegment-0.3.3-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.2->-r VITS/requirements_gptsovits.txt (line 1)) (3.0.1)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.2->-r VITS/requirements_gptsovits.txt (line 1)) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.2->-r VITS/requirements_gptsovits.txt (line 1)) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.2->-r VITS/requirements_gptsovits.txt (line 1)) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.2->-r VITS/requirements_gptsovits.txt (line 1)) (1.4.0)\n",
            "Requirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.2->-r VITS/requirements_gptsovits.txt (line 1)) (4.4.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.2->-r VITS/requirements_gptsovits.txt (line 1)) (0.4.3)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.2->-r VITS/requirements_gptsovits.txt (line 1)) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.2->-r VITS/requirements_gptsovits.txt (line 1)) (1.8.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.2->-r VITS/requirements_gptsovits.txt (line 1)) (24.0)\n",
            "Collecting llvmlite<0.40,>=0.39.0dev0 (from numba==0.56.4->-r VITS/requirements_gptsovits.txt (line 2))\n",
            "  Downloading llvmlite-0.39.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.6/34.6 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy>=1.17.0 (from librosa==0.9.2->-r VITS/requirements_gptsovits.txt (line 1))\n",
            "  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m78.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba==0.56.4->-r VITS/requirements_gptsovits.txt (line 2)) (67.7.2)\n",
            "Collecting addict (from modelscope==1.10.0->-r VITS/requirements_gptsovits.txt (line 12))\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from modelscope==1.10.0->-r VITS/requirements_gptsovits.txt (line 12)) (23.2.0)\n",
            "Collecting datasets>=2.14.5 (from modelscope==1.10.0->-r VITS/requirements_gptsovits.txt (line 12))\n",
            "  Downloading datasets-2.19.0-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops (from modelscope==1.10.0->-r VITS/requirements_gptsovits.txt (line 12))\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from modelscope==1.10.0->-r VITS/requirements_gptsovits.txt (line 12)) (3.13.4)\n",
            "Requirement already satisfied: gast>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from modelscope==1.10.0->-r VITS/requirements_gptsovits.txt (line 12)) (0.5.4)\n",
            "Collecting oss2 (from modelscope==1.10.0->-r VITS/requirements_gptsovits.txt (line 12))\n",
            "  Downloading oss2-2.18.4.tar.gz (278 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.1/278.1 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from modelscope==1.10.0->-r VITS/requirements_gptsovits.txt (line 12)) (2.0.3)\n",
            "Requirement already satisfied: Pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from modelscope==1.10.0->-r VITS/requirements_gptsovits.txt (line 12)) (9.4.0)\n",
            "Requirement already satisfied: pyarrow!=9.0.0,>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from modelscope==1.10.0->-r VITS/requirements_gptsovits.txt (line 12)) (14.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from modelscope==1.10.0->-r VITS/requirements_gptsovits.txt (line 12)) (2.8.2)\n",
            "Requirement already satisfied: requests>=2.25 in /usr/local/lib/python3.10/dist-packages (from modelscope==1.10.0->-r VITS/requirements_gptsovits.txt (line 12)) (2.31.0)\n",
            "Collecting simplejson>=3.3.0 (from modelscope==1.10.0->-r VITS/requirements_gptsovits.txt (line 12))\n",
            "  Downloading simplejson-3.19.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sortedcontainers>=1.5.9 in /usr/local/lib/python3.10/dist-packages (from modelscope==1.10.0->-r VITS/requirements_gptsovits.txt (line 12)) (2.4.0)\n",
            "Requirement already satisfied: urllib3>=1.26 in /usr/local/lib/python3.10/dist-packages (from modelscope==1.10.0->-r VITS/requirements_gptsovits.txt (line 12)) (2.0.7)\n",
            "Collecting yapf (from modelscope==1.10.0->-r VITS/requirements_gptsovits.txt (line 12))\n",
            "  Downloading yapf-0.40.2-py3-none-any.whl (254 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.7/254.7 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning->-r VITS/requirements_gptsovits.txt (line 3)) (2.2.1+cu121)\n",
            "Requirement already satisfied: fsspec[http]>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning->-r VITS/requirements_gptsovits.txt (line 3)) (2023.6.0)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning->-r VITS/requirements_gptsovits.txt (line 3))\n",
            "  Downloading torchmetrics-1.3.2-py3-none-any.whl (841 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m841.5/841.5 kB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning->-r VITS/requirements_gptsovits.txt (line 3)) (4.11.0)\n",
            "Collecting lightning-utilities>=0.8.0 (from pytorch-lightning->-r VITS/requirements_gptsovits.txt (line 3))\n",
            "  Downloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python->-r VITS/requirements_gptsovits.txt (line 4)) (0.18.3)\n",
            "Collecting coloredlogs (from onnxruntime->-r VITS/requirements_gptsovits.txt (line 5))\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime->-r VITS/requirements_gptsovits.txt (line 5)) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime->-r VITS/requirements_gptsovits.txt (line 5)) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime->-r VITS/requirements_gptsovits.txt (line 5)) (1.12)\n",
            "Collecting jamo (from funasr>=1.0.0->-r VITS/requirements_gptsovits.txt (line 7))\n",
            "  Downloading jamo-0.4.1-py3-none-any.whl (9.5 kB)\n",
            "Collecting kaldiio>=2.17.0 (from funasr>=1.0.0->-r VITS/requirements_gptsovits.txt (line 7))\n",
            "  Downloading kaldiio-2.18.0-py3-none-any.whl (28 kB)\n",
            "Collecting torch-complex (from funasr>=1.0.0->-r VITS/requirements_gptsovits.txt (line 7))\n",
            "  Downloading torch_complex-0.4.3-py3-none-any.whl (9.1 kB)\n",
            "Collecting rotary-embedding-torch (from funasr>=1.0.0->-r VITS/requirements_gptsovits.txt (line 7))\n",
            "  Downloading rotary_embedding_torch-0.5.3-py3-none-any.whl (5.3 kB)\n",
            "Collecting pytorch-wpe (from funasr>=1.0.0->-r VITS/requirements_gptsovits.txt (line 7))\n",
            "  Downloading pytorch_wpe-0.0.1-py3-none-any.whl (8.1 kB)\n",
            "Requirement already satisfied: editdistance>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from funasr>=1.0.0->-r VITS/requirements_gptsovits.txt (line 7)) (0.6.2)\n",
            "Collecting umap-learn (from funasr>=1.0.0->-r VITS/requirements_gptsovits.txt (line 7))\n",
            "  Downloading umap_learn-0.5.6-py3-none-any.whl (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jaconv (from funasr>=1.0.0->-r VITS/requirements_gptsovits.txt (line 7))\n",
            "  Downloading jaconv-0.3.4.tar.gz (16 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting hydra-core>=1.3.2 (from funasr>=1.0.0->-r VITS/requirements_gptsovits.txt (line 7))\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboardX (from funasr>=1.0.0->-r VITS/requirements_gptsovits.txt (line 7))\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai-whisper (from funasr>=1.0.0->-r VITS/requirements_gptsovits.txt (line 7))\n",
            "  Downloading openai-whisper-20231117.tar.gz (798 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.6/798.6 kB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting proces>=0.1.3 (from cn2an->-r VITS/requirements_gptsovits.txt (line 8))\n",
            "  Downloading proces-0.1.7-py3-none-any.whl (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.7/137.7 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pyopenjtalk->-r VITS/requirements_gptsovits.txt (line 10)) (1.16.0)\n",
            "Requirement already satisfied: nltk>=3.2.4 in /usr/local/lib/python3.10/dist-packages (from g2p_en->-r VITS/requirements_gptsovits.txt (line 11)) (3.8.1)\n",
            "Requirement already satisfied: inflect>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from g2p_en->-r VITS/requirements_gptsovits.txt (line 11)) (7.0.0)\n",
            "Collecting distance>=0.1.3 (from g2p_en->-r VITS/requirements_gptsovits.txt (line 11))\n",
            "  Downloading Distance-0.1.3.tar.gz (180 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.3/180.3 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py3langid>=0.2.2 (from LangSegment->-r VITS/requirements_gptsovits.txt (line 19))\n",
            "  Downloading py3langid-0.2.2-py3-none-any.whl (750 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.6/750.6 kB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.5->modelscope==1.10.0->-r VITS/requirements_gptsovits.txt (line 12)) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.14.5->modelscope==1.10.0->-r VITS/requirements_gptsovits.txt (line 12))\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash (from datasets>=2.14.5->modelscope==1.10.0->-r VITS/requirements_gptsovits.txt (line 12))\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets>=2.14.5->modelscope==1.10.0->-r VITS/requirements_gptsovits.txt (line 12))\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.5->modelscope==1.10.0->-r VITS/requirements_gptsovits.txt (line 12)) (3.9.5)\n",
            "Collecting huggingface-hub>=0.21.2 (from datasets>=2.14.5->modelscope==1.10.0->-r VITS/requirements_gptsovits.txt (line 12))\n",
            "  Downloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf<2.4,>=2.2 (from hydra-core>=1.3.2->funasr>=1.0.0->-r VITS/requirements_gptsovits.txt (line 7))\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.3.2->funasr>=1.0.0->-r VITS/requirements_gptsovits.txt (line 7))\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pydantic>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from inflect>=0.3.1->g2p_en->-r VITS/requirements_gptsovits.txt (line 11)) (2.7.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.4->g2p_en->-r VITS/requirements_gptsovits.txt (line 11)) (8.1.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.4->g2p_en->-r VITS/requirements_gptsovits.txt (line 11)) (2023.12.25)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa==0.9.2->-r VITS/requirements_gptsovits.txt (line 1)) (4.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25->modelscope==1.10.0->-r VITS/requirements_gptsovits.txt (line 12)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25->modelscope==1.10.0->-r VITS/requirements_gptsovits.txt (line 12)) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25->modelscope==1.10.0->-r VITS/requirements_gptsovits.txt (line 12)) (2024.2.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->librosa==0.9.2->-r VITS/requirements_gptsovits.txt (line 1)) (3.4.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.10.2->librosa==0.9.2->-r VITS/requirements_gptsovits.txt (line 1)) (1.16.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning->-r VITS/requirements_gptsovits.txt (line 3)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning->-r VITS/requirements_gptsovits.txt (line 3)) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning->-r VITS/requirements_gptsovits.txt (line 3)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning->-r VITS/requirements_gptsovits.txt (line 3)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning->-r VITS/requirements_gptsovits.txt (line 3)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning->-r VITS/requirements_gptsovits.txt (line 3)) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning->-r VITS/requirements_gptsovits.txt (line 3)) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning->-r VITS/requirements_gptsovits.txt (line 3)) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning->-r VITS/requirements_gptsovits.txt (line 3)) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning->-r VITS/requirements_gptsovits.txt (line 3)) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning->-r VITS/requirements_gptsovits.txt (line 3)) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning->-r VITS/requirements_gptsovits.txt (line 3)) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning->-r VITS/requirements_gptsovits.txt (line 3)) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning->-r VITS/requirements_gptsovits.txt (line 3)) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->pytorch-lightning->-r VITS/requirements_gptsovits.txt (line 3)) (12.4.127)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime->-r VITS/requirements_gptsovits.txt (line 5))\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper->funasr>=1.0.0->-r VITS/requirements_gptsovits.txt (line 7)) (10.1.0)\n",
            "Collecting tiktoken (from openai-whisper->funasr>=1.0.0->-r VITS/requirements_gptsovits.txt (line 7))\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting crcmod>=1.7 (from oss2->modelscope==1.10.0->-r VITS/requirements_gptsovits.txt (line 12))\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pycryptodome>=3.4.7 (from oss2->modelscope==1.10.0->-r VITS/requirements_gptsovits.txt (line 12))\n",
            "  Downloading pycryptodome-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aliyun-python-sdk-kms>=2.4.1 (from oss2->modelscope==1.10.0->-r VITS/requirements_gptsovits.txt (line 12))\n",
            "  Downloading aliyun_python_sdk_kms-2.16.2-py2.py3-none-any.whl (94 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.0/94.0 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aliyun-python-sdk-core>=2.13.12 (from oss2->modelscope==1.10.0->-r VITS/requirements_gptsovits.txt (line 12))\n",
            "  Downloading aliyun-python-sdk-core-2.15.1.tar.gz (443 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.1/443.1 kB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->modelscope==1.10.0->-r VITS/requirements_gptsovits.txt (line 12)) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->modelscope==1.10.0->-r VITS/requirements_gptsovits.txt (line 12)) (2024.1)\n",
            "Collecting beartype (from rotary-embedding-torch->funasr>=1.0.0->-r VITS/requirements_gptsovits.txt (line 7))\n",
            "  Downloading beartype-0.18.5-py3-none-any.whl (917 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m917.8/917.8 kB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime->-r VITS/requirements_gptsovits.txt (line 5)) (1.3.0)\n",
            "Collecting pynndescent>=0.5 (from umap-learn->funasr>=1.0.0->-r VITS/requirements_gptsovits.txt (line 7))\n",
            "  Downloading pynndescent-0.5.12-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf->modelscope==1.10.0->-r VITS/requirements_gptsovits.txt (line 12)) (7.1.0)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->modelscope==1.10.0->-r VITS/requirements_gptsovits.txt (line 12)) (2.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.5->modelscope==1.10.0->-r VITS/requirements_gptsovits.txt (line 12)) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.5->modelscope==1.10.0->-r VITS/requirements_gptsovits.txt (line 12)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.5->modelscope==1.10.0->-r VITS/requirements_gptsovits.txt (line 12)) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.5->modelscope==1.10.0->-r VITS/requirements_gptsovits.txt (line 12)) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.5->modelscope==1.10.0->-r VITS/requirements_gptsovits.txt (line 12)) (4.0.3)\n",
            "Collecting jmespath<1.0.0,>=0.9.3 (from aliyun-python-sdk-core>=2.13.12->oss2->modelscope==1.10.0->-r VITS/requirements_gptsovits.txt (line 12))\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: cryptography>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2->modelscope==1.10.0->-r VITS/requirements_gptsovits.txt (line 12)) (42.0.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa==0.9.2->-r VITS/requirements_gptsovits.txt (line 1)) (2.22)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->modelscope==1.10.0->-r VITS/requirements_gptsovits.txt (line 12)) (3.18.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.1->inflect>=0.3.1->g2p_en->-r VITS/requirements_gptsovits.txt (line 11)) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.1->inflect>=0.3.1->g2p_en->-r VITS/requirements_gptsovits.txt (line 11)) (2.18.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->pytorch-lightning->-r VITS/requirements_gptsovits.txt (line 3)) (2.1.5)\n",
            "Building wheels for collected packages: pyopenjtalk, jieba_fast, distance, antlr4-python3-runtime, jaconv, openai-whisper, oss2, aliyun-python-sdk-core, crcmod\n",
            "  Building wheel for pyopenjtalk (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyopenjtalk: filename=pyopenjtalk-0.3.3-cp310-cp310-linux_x86_64.whl size=5354576 sha256=8e0fe53bfa388e2af4258716231d3319ce48583a799512eecbef7cbb80d27b14\n",
            "  Stored in directory: /root/.cache/pip/wheels/64/a9/5f/19eedcf7741bcd1494dc8782b6842e433314793492cc9167c9\n",
            "  Building wheel for jieba_fast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jieba_fast: filename=jieba_fast-0.53-cp310-cp310-linux_x86_64.whl size=7658019 sha256=b3850cc42abd9712352fc6169e4124fdce8cb25cc9555cc07c91fd50b7131dda\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/bc/2e/ec85cb24f946d722725b17fc7aa1afca0c2dcfd727d540a06a\n",
            "  Building wheel for distance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for distance: filename=Distance-0.1.3-py3-none-any.whl size=16258 sha256=ef4090329d214ea6ad1d1e69a943fd5e0fd0c314e20738452d3226c0801d4205\n",
            "  Stored in directory: /root/.cache/pip/wheels/e8/bb/de/f71bf63559ea9a921059a5405806f7ff6ed612a9231c4a9309\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=d938ce8f22b42d0d9439d9918ffd14d0fbce29badfef2015798e51e02cc3cb13\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "  Building wheel for jaconv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jaconv: filename=jaconv-0.3.4-py3-none-any.whl size=16416 sha256=3fd5ea8799816df08585bd67a2fb182492e0002dcbde3a0e10761f769da4a59a\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/8f/2e/a730bf1fca05b33e532d5d91dabdf406c9b718ec85b01b1b54\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=801358 sha256=2899c43986f0aa59f89357073f6ec334ed2d9a8faf66a68cfadad4fe2657816a\n",
            "  Stored in directory: /root/.cache/pip/wheels/d0/85/e1/9361b4cbea7dd4b7f6702fa4c3afc94877952eeb2b62f45f56\n",
            "  Building wheel for oss2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for oss2: filename=oss2-2.18.4-py3-none-any.whl size=115939 sha256=e9b9be3d7159750c727d8d9d4c65e58bfa889d747cba99a112b090489a76247b\n",
            "  Stored in directory: /root/.cache/pip/wheels/9e/34/68/f21dc0320c699eb02ab90f2f7965d6f60ee793f03ef5e23212\n",
            "  Building wheel for aliyun-python-sdk-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for aliyun-python-sdk-core: filename=aliyun_python_sdk_core-2.15.1-py3-none-any.whl size=535325 sha256=59b4be1db81465f7d45ca24ceffd844505ed18da2e789b9283ee57e32b18867c\n",
            "  Stored in directory: /root/.cache/pip/wheels/69/4b/8e/0a28e00f4cf43b273c18cce083804738d41013e017da922ce4\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=31406 sha256=37db238a7ecff300ee5c488b1c28e384a47d0e25581787dec0534bfa01a5bf5e\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
            "Successfully built pyopenjtalk jieba_fast distance antlr4-python3-runtime jaconv openai-whisper oss2 aliyun-python-sdk-core crcmod\n",
            "Installing collected packages: jieba_fast, jamo, jaconv, distance, crcmod, antlr4-python3-runtime, addict, xxhash, simplejson, pypinyin, pycryptodome, proces, omegaconf, numpy, llvmlite, lightning-utilities, jmespath, humanfriendly, einops, dill, beartype, yapf, torch-complex, tiktoken, tensorboardX, pytorch-wpe, pyopenjtalk, py3langid, numba, multiprocess, kaldiio, hydra-core, huggingface-hub, coloredlogs, cn2an, onnxruntime, LangSegment, aliyun-python-sdk-core, torchmetrics, rotary-embedding-torch, pynndescent, openai-whisper, librosa, g2p_en, datasets, aliyun-python-sdk-kms, umap-learn, pytorch-lightning, oss2, modelscope, funasr\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.41.1\n",
            "    Uninstalling llvmlite-0.41.1:\n",
            "      Successfully uninstalled llvmlite-0.41.1\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.58.1\n",
            "    Uninstalling numba-0.58.1:\n",
            "      Successfully uninstalled numba-0.58.1\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.20.3\n",
            "    Uninstalling huggingface-hub-0.20.3:\n",
            "      Successfully uninstalled huggingface-hub-0.20.3\n",
            "  Attempting uninstall: librosa\n",
            "    Found existing installation: librosa 0.9.1\n",
            "    Uninstalling librosa-0.9.1:\n",
            "      Successfully uninstalled librosa-0.9.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "chex 0.1.86 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "pandas-stubs 2.0.3.230814 requires numpy>=1.25.0; python_version >= \"3.9\", but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed LangSegment-0.3.3 addict-2.4.0 aliyun-python-sdk-core-2.15.1 aliyun-python-sdk-kms-2.16.2 antlr4-python3-runtime-4.9.3 beartype-0.18.5 cn2an-0.5.22 coloredlogs-15.0.1 crcmod-1.7 datasets-2.19.0 dill-0.3.8 distance-0.1.3 einops-0.7.0 funasr-1.0.25 g2p_en-2.1.0 huggingface-hub-0.22.2 humanfriendly-10.0 hydra-core-1.3.2 jaconv-0.3.4 jamo-0.4.1 jieba_fast-0.53 jmespath-0.10.0 kaldiio-2.18.0 librosa-0.9.2 lightning-utilities-0.11.2 llvmlite-0.39.1 modelscope-1.10.0 multiprocess-0.70.16 numba-0.56.4 numpy-1.23.5 omegaconf-2.3.0 onnxruntime-1.17.3 openai-whisper-20231117 oss2-2.18.4 proces-0.1.7 py3langid-0.2.2 pycryptodome-3.20.0 pynndescent-0.5.12 pyopenjtalk-0.3.3 pypinyin-0.51.0 pytorch-lightning-2.2.3 pytorch-wpe-0.0.1 rotary-embedding-torch-0.5.3 simplejson-3.19.2 tensorboardX-2.6.2.2 tiktoken-0.6.0 torch-complex-0.4.3 torchmetrics-1.3.2 umap-learn-0.5.6 xxhash-3.4.1 yapf-0.40.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "pydevd_plugins"
                ]
              },
              "id": "406f3b56c2104acab977d6ce4fd4529f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-4.27.0-py3-none-any.whl (17.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.110.2-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.9/91.9 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.15.1 (from gradio)\n",
            "  Downloading gradio_client-0.15.1-py3-none-any.whl (313 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx>=0.24.1 (from gradio)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.22.2)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.3)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.23.5)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.7.0)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.4.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Collecting typer<1.0,>=0.12 (from gradio)\n",
            "  Downloading typer-0.12.3-py3-none-any.whl (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.11.0)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.15.1->gradio) (2023.6.0)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==0.15.1->gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.13.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.18.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->gradio)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.34.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio) (1.2.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=33eabad1b2b01c24ddc7858cfa6146a7d1f05ccfe4b62c350cbba6e0acb1cc42\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pydub, ffmpy, websockets, tomlkit, shellingham, semantic-version, ruff, python-multipart, orjson, h11, aiofiles, uvicorn, starlette, httpcore, typer, httpx, fastapi, gradio-client, gradio\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.9.4\n",
            "    Uninstalling typer-0.9.4:\n",
            "      Successfully uninstalled typer-0.9.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "spacy 3.7.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n",
            "weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.2.1 fastapi-0.110.2 ffmpy-0.3.2 gradio-4.27.0 gradio-client-0.15.1 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 orjson-3.10.1 pydub-0.25.1 python-multipart-0.0.9 ruff-0.4.1 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.37.2 tomlkit-0.12.0 typer-0.12.3 uvicorn-0.29.0 websockets-11.0.3\n",
            "Updated git hooks.\n",
            "Git LFS initialized.\n",
            "Cloning into 'Linly-Talker'...\n",
            "remote: Enumerating objects: 97, done.\u001b[K\n",
            "remote: Counting objects: 100% (93/93), done.\u001b[K\n",
            "remote: Compressing objects: 100% (84/84), done.\u001b[K\n",
            "remote: Total 97 (delta 15), reused 0 (delta 0), pack-reused 4\u001b[K\n",
            "Unpacking objects: 100% (97/97), 4.34 MiB | 5.71 MiB/s, done.\n",
            "Filtering content: 100% (23/23), 7.05 GiB | 50.17 MiB/s, done.\n",
            "/content/Linly-Talker\n",
            "mkdir: cannot create directory ‘checkpoints’: File exists\n",
            "['/content', '/env/python', '/usr/lib/python310.zip', '/usr/lib/python3.10', '/usr/lib/python3.10/lib-dynload', '', '/usr/local/lib/python3.10/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.10/dist-packages/IPython/extensions', '/root/.ipython']\n",
            "Collecting TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1 (from -r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2))\n",
            "  Cloning https://github.com/coqui-ai/TTS (to revision v0.21.1) to /tmp/pip-install-6l75db72/tts_1f8c9b8ad4e74283ab856c86f63eadd8\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/coqui-ai/TTS /tmp/pip-install-6l75db72/tts_1f8c9b8ad4e74283ab856c86f63eadd8\n",
            "  Running command git checkout -q 00a870c26abdc06429ffef3e2814b1a1d5b40fff\n",
            "  Resolved https://github.com/coqui-ai/TTS to commit 00a870c26abdc06429ffef3e2814b1a1d5b40fff\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pydantic==1.10.13 (from -r /content/Linly-Talker/VITS/requirements_xtts.txt (line 3))\n",
            "  Downloading pydantic-1.10.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-multipart==0.0.6 (from -r /content/Linly-Talker/VITS/requirements_xtts.txt (line 4))\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/Linly-Talker/VITS/requirements_xtts.txt (line 5)) (4.11.0)\n",
            "Collecting cutlet (from -r /content/Linly-Talker/VITS/requirements_xtts.txt (line 6))\n",
            "  Downloading cutlet-0.4.0.tar.gz (412 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.3/412.3 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mecab-python3==1.0.6 (from -r /content/Linly-Talker/VITS/requirements_xtts.txt (line 7))\n",
            "  Downloading mecab_python3-1.0.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (581 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m581.6/581.6 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting unidic-lite==1.0.8 (from -r /content/Linly-Talker/VITS/requirements_xtts.txt (line 8))\n",
            "  Downloading unidic-lite-1.0.8.tar.gz (47.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.4/47.4 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting unidic==1.1.0 (from -r /content/Linly-Talker/VITS/requirements_xtts.txt (line 9))\n",
            "  Downloading unidic-1.1.0.tar.gz (7.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting langid (from -r /content/Linly-Talker/VITS/requirements_xtts.txt (line 10))\n",
            "  Downloading langid-1.1.6.tar.gz (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m76.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting deepspeed (from -r /content/Linly-Talker/VITS/requirements_xtts.txt (line 11))\n",
            "  Downloading deepspeed-0.14.2.tar.gz (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from -r /content/Linly-Talker/VITS/requirements_xtts.txt (line 12)) (0.25.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from unidic==1.1.0->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 9)) (2.31.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.41.1 in /usr/local/lib/python3.10/dist-packages (from unidic==1.1.0->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 9)) (4.66.2)\n",
            "Collecting wasabi<1.0.0,>=0.6.0 (from unidic==1.1.0->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 9))\n",
            "  Downloading wasabi-0.10.1-py3-none-any.whl (26 kB)\n",
            "Collecting plac<2.0.0,>=1.1.3 (from unidic==1.1.0->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 9))\n",
            "  Downloading plac-1.4.3-py2.py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: cython>=0.29.30 in /usr/local/lib/python3.10/dist-packages (from TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (3.0.10)\n",
            "Requirement already satisfied: scipy>=1.11.2 in /usr/local/lib/python3.10/dist-packages (from TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (1.11.4)\n",
            "Requirement already satisfied: torch>=2.1 in /usr/local/lib/python3.10/dist-packages (from TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (2.2.1+cu121)\n",
            "Requirement already satisfied: soundfile>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (0.12.1)\n",
            "Collecting librosa>=0.10.0 (from TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2))\n",
            "  Downloading librosa-0.10.1-py3-none-any.whl (253 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.7/253.7 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn>=1.3.0 (from TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2))\n",
            "  Downloading scikit_learn-1.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: inflect>=5.6.0 in /usr/local/lib/python3.10/dist-packages (from TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (7.0.0)\n",
            "Collecting anyascii>=0.3.0 (from TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2))\n",
            "  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=6.0 in /usr/local/lib/python3.10/dist-packages (from TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (6.0.1)\n",
            "Requirement already satisfied: fsspec>=2023.6.0 in /usr/local/lib/python3.10/dist-packages (from TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (3.9.5)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.10/dist-packages (from TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (24.0)\n",
            "Requirement already satisfied: flask>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (2.2.5)\n",
            "Collecting pysbd>=0.3.4 (from TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2))\n",
            "  Downloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: umap-learn>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (0.5.6)\n",
            "Collecting pandas<2.0,>=1.4 (from TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2))\n",
            "  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (3.7.1)\n",
            "Collecting trainer>=0.0.32 (from TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2))\n",
            "  Downloading trainer-0.0.36-py3-none-any.whl (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.2/51.2 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coqpit>=0.0.16 (from TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2))\n",
            "  Downloading coqpit-0.0.17-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (0.42.1)\n",
            "Requirement already satisfied: pypinyin in /usr/local/lib/python3.10/dist-packages (from TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (0.51.0)\n",
            "Collecting hangul-romanize (from TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2))\n",
            "  Downloading hangul_romanize-0.1.0-py3-none-any.whl (4.6 kB)\n",
            "Collecting gruut[de,es,fr]==2.2.3 (from TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2))\n",
            "  Downloading gruut-2.2.3.tar.gz (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jamo in /usr/local/lib/python3.10/dist-packages (from TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (0.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (3.8.1)\n",
            "Collecting g2pkk>=0.1.1 (from TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2))\n",
            "  Downloading g2pkk-0.1.2-py3-none-any.whl (25 kB)\n",
            "Collecting bangla (from TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2))\n",
            "  Downloading bangla-0.0.2-py2.py3-none-any.whl (6.2 kB)\n",
            "Collecting bnnumerizer (from TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2))\n",
            "  Downloading bnnumerizer-0.0.2.tar.gz (4.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting bnunicodenormalizer (from TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2))\n",
            "  Downloading bnunicodenormalizer-0.1.6.tar.gz (39 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (0.7.0)\n",
            "Requirement already satisfied: transformers>=4.33.0 in /usr/local/lib/python3.10/dist-packages (from TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (4.40.0)\n",
            "Collecting encodec>=0.1.1 (from TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2))\n",
            "  Downloading encodec-0.1.1.tar.gz (3.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m101.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting unidecode>=1.3.2 (from TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2))\n",
            "  Downloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting num2words (from TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2))\n",
            "  Downloading num2words-0.5.13-py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.3/143.3 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy[ja]>=3 in /usr/local/lib/python3.10/dist-packages (from TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (3.7.4)\n",
            "Collecting numpy==1.22.0 (from TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2))\n",
            "  Downloading numpy-1.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numba>=0.57.0 (from TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2))\n",
            "  Downloading numba-0.59.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m93.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Babel<3.0.0,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (2.14.0)\n",
            "Collecting dateparser~=1.1.0 (from gruut[de,es,fr]==2.2.3->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2))\n",
            "  Downloading dateparser-1.1.8-py2.py3-none-any.whl (293 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.8/293.8 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gruut-ipa<1.0,>=0.12.0 (from gruut[de,es,fr]==2.2.3->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2))\n",
            "  Downloading gruut-ipa-0.13.0.tar.gz (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gruut_lang_en~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2))\n",
            "  Downloading gruut_lang_en-2.0.0.tar.gz (15.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.2/15.2 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jsonlines~=1.2.0 (from gruut[de,es,fr]==2.2.3->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2))\n",
            "  Downloading jsonlines-1.2.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting networkx<3.0.0,>=2.5.0 (from gruut[de,es,fr]==2.2.3->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2))\n",
            "  Downloading networkx-2.8.8-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-crfsuite~=0.9.7 (from gruut[de,es,fr]==2.2.3->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2))\n",
            "  Downloading python_crfsuite-0.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gruut_lang_es~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2))\n",
            "  Downloading gruut_lang_es-2.0.0.tar.gz (31.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gruut_lang_de~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2))\n",
            "  Downloading gruut_lang_de-2.0.0.tar.gz (18.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gruut_lang_fr~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2))\n",
            "  Downloading gruut_lang_fr-2.0.2.tar.gz (10.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jaconv in /usr/local/lib/python3.10/dist-packages (from cutlet->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 6)) (0.3.4)\n",
            "Collecting fugashi (from cutlet->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 6))\n",
            "  Downloading fugashi-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (600 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m600.9/600.9 kB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mojimoji (from cutlet->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 6))\n",
            "  Downloading mojimoji-0.0.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (192 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.4/192.4 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hjson (from deepspeed->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 11))\n",
            "  Downloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ninja (from deepspeed->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 11))\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from deepspeed->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 11)) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from deepspeed->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 11)) (9.0.0)\n",
            "Collecting pynvml (from deepspeed->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 11))\n",
            "  Downloading pynvml-11.5.0-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (4.0.3)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask>=2.0.1->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (3.0.2)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from flask>=2.0.1->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (3.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask>=2.0.1->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (2.2.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask>=2.0.1->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (8.1.7)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (3.0.1)\n",
            "INFO: pip is looking at multiple versions of librosa to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting librosa>=0.10.0 (from TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2))\n",
            "  Downloading librosa-0.10.0.post2-py3-none-any.whl (253 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading librosa-0.10.0.post1-py3-none-any.whl (252 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading librosa-0.10.0-py3-none-any.whl (252 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.9/252.9 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (1.4.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (1.8.1)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (0.3.7)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (1.0.8)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (2.8.2)\n",
            "Collecting docopt>=0.6.2 (from num2words->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2))\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting llvmlite<0.43,>=0.42.0dev0 (from numba>=0.57.0->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2))\n",
            "  Downloading llvmlite-0.42.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0,>=1.4->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (2023.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.22.0->unidic==1.1.0->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 9)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.22.0->unidic==1.1.0->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 9)) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.22.0->unidic==1.1.0->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 9)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.22.0->unidic==1.1.0->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 9)) (2024.2.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (3.4.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.0->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (1.16.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (8.2.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (0.3.4)\n",
            "Collecting typer<0.10.0,>=0.3.0 (from spacy[ja]>=3->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2))\n",
            "  Downloading typer-0.9.4-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (6.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (67.7.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (3.3.0)\n",
            "Collecting sudachipy!=0.6.1,>=0.5.2 (from spacy[ja]>=3->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2))\n",
            "  Downloading SudachiPy-0.6.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sudachidict-core>=20211220 (from spacy[ja]>=3->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2))\n",
            "  Downloading SudachiDict_core-20240409-py3-none-any.whl (72.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (3.13.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (1.12)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.1->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (12.4.127)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from trainer>=0.0.32->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (2.15.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.33.0->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (0.22.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.33.0->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.33.0->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.33.0->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (0.4.3)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.10/dist-packages (from umap-learn>=0.5.1->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (0.5.12)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.0->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (2.22)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from dateparser~=1.1.0->gruut[de,es,fr]==2.2.3->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (5.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->flask>=2.0.1->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (2.1.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from jsonlines~=1.2.0->gruut[de,es,fr]==2.2.3->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (1.16.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa>=0.10.0->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (4.2.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy[ja]>=3->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy[ja]>=3->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (0.1.4)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy[ja]>=3->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (0.16.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.1->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (1.62.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (3.6)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (3.20.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (0.7.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->trainer>=0.0.32->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->trainer>=0.0.32->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->trainer>=0.0.32->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->trainer>=0.0.32->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->trainer>=0.0.32->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->trainer>=0.0.32->TTS@ git+https://github.com/coqui-ai/TTS@v0.21.1->-r /content/Linly-Talker/VITS/requirements_xtts.txt (line 2)) (3.2.2)\n",
            "Building wheels for collected packages: unidic-lite, unidic, TTS, cutlet, langid, deepspeed, encodec, bnnumerizer, bnunicodenormalizer, docopt, gruut-ipa, gruut_lang_de, gruut_lang_en, gruut_lang_es, gruut_lang_fr, gruut\n",
            "  Building wheel for unidic-lite (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for unidic-lite: filename=unidic_lite-1.0.8-py3-none-any.whl size=47658818 sha256=fd9bdd4c1d338669714a515f6ea672b78043e837bea06e9bd13d09c5ed282cc4\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/e8/68/f9ac36b8cc6c8b3c96888cd57434abed96595d444f42243853\n",
            "  Building wheel for unidic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for unidic: filename=unidic-1.1.0-py3-none-any.whl size=7406 sha256=f976ef6035e082105a124e46c3ba776e251f0e00574b538cd5e3b531976ff5b3\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/72/72/1f3d654c345ea69d5d51b531c90daf7ba14cc555eaf2c64ab0\n",
            "  Building wheel for TTS (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for TTS: filename=TTS-0.21.1-cp310-cp310-linux_x86_64.whl size=898702 sha256=1919639a3ae06defda3f706cd164d60ef8c71edd10b02ad400dad01add23c98e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-hdjms08n/wheels/82/c3/55/5867000d5ab1d8e6d1e84e6026b4e08b662facdfd0ce130820\n",
            "  Building wheel for cutlet (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cutlet: filename=cutlet-0.4.0-py3-none-any.whl size=11677 sha256=6d0310991ed6627df60aca226622ed9734098553253b5015d7fdeb46c32e1384\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/29/e4/7b41fa990a65ee871955d9700653236223ae1abdfdf9244e53\n",
            "  Building wheel for langid (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langid: filename=langid-1.1.6-py3-none-any.whl size=1941172 sha256=2f9ea6797601eaf6e7c7ee948d1ce53e5b9d680c521a3786cdbd8b0a35accf31\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/c8/c6/eed80894918490a175677414d40bd7c851413bbe03d4856c3c\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepspeed: filename=deepspeed-0.14.2-py3-none-any.whl size=1432238 sha256=abb55a01a73f9ac0f57579faa7129de199e3fcff7c821c840f725d088781003e\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/7c/43/bed44d8414c099ff962b754f425f7ff77cc623cc8a98e0da70\n",
            "  Building wheel for encodec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for encodec: filename=encodec-0.1.1-py3-none-any.whl size=45762 sha256=26526c9fa9fa52d0b561a266498307cec74d6395411f502d343ff0f84b966a2d\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/36/cb/81af8b985a5f5e0815312d5e52b41263237af07b977e6bcbf3\n",
            "  Building wheel for bnnumerizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bnnumerizer: filename=bnnumerizer-0.0.2-py3-none-any.whl size=5261 sha256=862fee89a589aa49256fa4af8ae8ce450728c17551fe99997f93b8602d0d0408\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/6b/e8/223172e7d5c9f72df3ea1a0d9258f3a8ab5b28e827728edef5\n",
            "  Building wheel for bnunicodenormalizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bnunicodenormalizer: filename=bnunicodenormalizer-0.1.6-py3-none-any.whl size=22780 sha256=e05efbe2fc8c5e003c57bbf5fad6c86b3474daab1b5f592ccd68de45b6beeaa1\n",
            "  Stored in directory: /root/.cache/pip/wheels/f4/d7/e9/16732a619cbf5a63fdc9f6e2f9eb5fcf73fa023735237330e9\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=62871743ba727ac9eedc28eadf0930a258e92eec73b8aa5b5c4b0d7e6a7f2d58\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "  Building wheel for gruut-ipa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut-ipa: filename=gruut_ipa-0.13.0-py3-none-any.whl size=104870 sha256=193bda0df24417d99a0f3b55a7a37f9d0ef540aa75f7e39e6b2caf9a8e8f27fe\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/18/49/e4f500ecdf0babe757953f844e4d7cd1ea81c5503c09bfe984\n",
            "  Building wheel for gruut_lang_de (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_de: filename=gruut_lang_de-2.0.0-py3-none-any.whl size=18498183 sha256=e96a4d3da744564c57c0b801fb9daab245ab6d0636d21cd1f58eca8ccea24e40\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/9a/05/cfce98f0c41a1a540f15708c4a02df190b82d84cf91ef6bc7f\n",
            "  Building wheel for gruut_lang_en (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_en: filename=gruut_lang_en-2.0.0-py3-none-any.whl size=15297178 sha256=780ca0caab76f8e2a19c3c70d341ee2529302b6a75586b357f15b0bcacb36b96\n",
            "  Stored in directory: /root/.cache/pip/wheels/10/9c/fb/77c655a9fbd78cdb9935d0ab65d80ddd0a3bcf7dbe18261650\n",
            "  Building wheel for gruut_lang_es (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_es: filename=gruut_lang_es-2.0.0-py3-none-any.whl size=32173797 sha256=f866bcead5d71c3a6eae63c98053410de7db6fb504443e50feb926e89e7a3689\n",
            "  Stored in directory: /root/.cache/pip/wheels/9b/0a/90/788d92c07744b329b9283e37b29b064f5db6b1bb0442a1a19b\n",
            "  Building wheel for gruut_lang_fr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_fr: filename=gruut_lang_fr-2.0.2-py3-none-any.whl size=10968767 sha256=b955e864ac4c3e58dbba809022bc05e178f8aae1ebfa19a56f98f82eed79fa5c\n",
            "  Stored in directory: /root/.cache/pip/wheels/db/21/be/d0436e3f1cf9bf38b9bb9b4a476399c77a1ab19f7172b45e19\n",
            "  Building wheel for gruut (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut: filename=gruut-2.2.3-py3-none-any.whl size=75791 sha256=b8d39328fdcbb58d65c02366f2a6b571b52db144171892a450d2880078f8c53a\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/57/a8/f9de532daf5214f53644f20f3a9e6f69269453c87df9c0a817\n",
            "Successfully built unidic-lite unidic TTS cutlet langid deepspeed encodec bnnumerizer bnunicodenormalizer docopt gruut-ipa gruut_lang_de gruut_lang_en gruut_lang_es gruut_lang_fr gruut\n",
            "Installing collected packages: wasabi, unidic-lite, sudachipy, python-crfsuite, plac, ninja, mecab-python3, hjson, hangul-romanize, gruut_lang_fr, gruut_lang_es, gruut_lang_en, gruut_lang_de, docopt, bnunicodenormalizer, bnnumerizer, bangla, unidecode, typer, sudachidict-core, python-multipart, pysbd, pynvml, pydantic, numpy, num2words, networkx, mojimoji, llvmlite, jsonlines, gruut-ipa, fugashi, coqpit, anyascii, unidic, pandas, numba, langid, g2pkk, dateparser, cutlet, scikit-learn, gruut, librosa, deepspeed, trainer, encodec, TTS\n",
            "  Attempting uninstall: wasabi\n",
            "    Found existing installation: wasabi 1.1.2\n",
            "    Uninstalling wasabi-1.1.2:\n",
            "      Successfully uninstalled wasabi-1.1.2\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.12.3\n",
            "    Uninstalling typer-0.12.3:\n",
            "      Successfully uninstalled typer-0.12.3\n",
            "  Attempting uninstall: python-multipart\n",
            "    Found existing installation: python-multipart 0.0.9\n",
            "    Uninstalling python-multipart-0.0.9:\n",
            "      Successfully uninstalled python-multipart-0.0.9\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.7.0\n",
            "    Uninstalling pydantic-2.7.0:\n",
            "      Successfully uninstalled pydantic-2.7.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.23.5\n",
            "    Uninstalling numpy-1.23.5:\n",
            "      Successfully uninstalled numpy-1.23.5\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.3\n",
            "    Uninstalling networkx-3.3:\n",
            "      Successfully uninstalled networkx-3.3\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.39.1\n",
            "    Uninstalling llvmlite-0.39.1:\n",
            "      Successfully uninstalled llvmlite-0.39.1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.0.3\n",
            "    Uninstalling pandas-2.0.3:\n",
            "      Successfully uninstalled pandas-2.0.3\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.56.4\n",
            "    Uninstalling numba-0.56.4:\n",
            "      Successfully uninstalled numba-0.56.4\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "  Attempting uninstall: librosa\n",
            "    Found existing installation: librosa 0.9.2\n",
            "    Uninstalling librosa-0.9.2:\n",
            "      Successfully uninstalled librosa-0.9.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "chex 0.1.86 requires numpy>=1.24.1, but you have numpy 1.22.0 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.0.3, but you have pandas 1.5.3 which is incompatible.\n",
            "gradio 4.27.0 requires pydantic>=2.0, but you have pydantic 1.10.13 which is incompatible.\n",
            "gradio 4.27.0 requires python-multipart>=0.0.9, but you have python-multipart 0.0.6 which is incompatible.\n",
            "gradio 4.27.0 requires typer<1.0,>=0.12; sys_platform != \"emscripten\", but you have typer 0.9.4 which is incompatible.\n",
            "pandas-stubs 2.0.3.230814 requires numpy>=1.25.0; python_version >= \"3.9\", but you have numpy 1.22.0 which is incompatible.\n",
            "plotnine 0.12.4 requires numpy>=1.23.0, but you have numpy 1.22.0 which is incompatible.\n",
            "pywavelets 1.6.0 requires numpy<3,>=1.22.4, but you have numpy 1.22.0 which is incompatible.\n",
            "statsmodels 0.14.2 requires numpy>=1.22.3, but you have numpy 1.22.0 which is incompatible.\n",
            "tensorflow 2.15.0 requires numpy<2.0.0,>=1.23.5, but you have numpy 1.22.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed TTS-0.21.1 anyascii-0.3.2 bangla-0.0.2 bnnumerizer-0.0.2 bnunicodenormalizer-0.1.6 coqpit-0.0.17 cutlet-0.4.0 dateparser-1.1.8 deepspeed-0.14.2 docopt-0.6.2 encodec-0.1.1 fugashi-1.3.2 g2pkk-0.1.2 gruut-2.2.3 gruut-ipa-0.13.0 gruut_lang_de-2.0.0 gruut_lang_en-2.0.0 gruut_lang_es-2.0.0 gruut_lang_fr-2.0.2 hangul-romanize-0.1.0 hjson-3.1.0 jsonlines-1.2.0 langid-1.1.6 librosa-0.10.0 llvmlite-0.42.0 mecab-python3-1.0.6 mojimoji-0.0.13 networkx-2.8.8 ninja-1.11.1.1 num2words-0.5.13 numba-0.59.1 numpy-1.22.0 pandas-1.5.3 plac-1.4.3 pydantic-1.10.13 pynvml-11.5.0 pysbd-0.3.4 python-crfsuite-0.9.10 python-multipart-0.0.6 scikit-learn-1.4.2 sudachidict-core-20240409 sudachipy-0.6.8 trainer-0.0.36 typer-0.9.4 unidecode-1.3.8 unidic-1.1.0 unidic-lite-1.0.8 wasabi-0.10.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "27cea3bcc45d4debb1685a3283985bf1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/cmudict.zip.\n",
            "Some weights of the model checkpoint at GPT_SoVITS/pretrained_models/chinese-hubert-base were not used when initializing HubertModel: ['encoder.pos_conv_embed.conv.weight_g', 'encoder.pos_conv_embed.conv.weight_v']\n",
            "- This IS expected if you are initializing HubertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing HubertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of HubertModel were not initialized from the model checkpoint at GPT_SoVITS/pretrained_models/chinese-hubert-base and are newly initialized: ['encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT_SoVITS导入成功\n",
            "XTTS导入失败，原因： cannot import name 'RootModel' from 'pydantic' (/usr/local/lib/python3.10/dist-packages/pydantic/__init__.cpython-310-x86_64-linux-gnu.so)\n",
            "使用XTTS语音克隆前需要安装对应的环境，请执行 pip install -r VITS/requirements_xtts.txt\n",
            "文件 2.docx 已移动到 /content/doc_folder\n",
            "文件 3.docx 已移动到 /content/doc_folder\n",
            "文件 1.docx 已移动到 /content/doc_folder\n",
            "Number of parameter: 77.49M\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
            "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<All keys matched successfully>\n",
            "/content/drive/MyDrive/语音权重/20240329.wav_0000156800_0000395200.wav 那我们物联网概论总共分为三个章节，好，第一章首先要和大家介绍的是物联网的简介。 中文 大家好，歡迎來到這門課，人工智慧思維與創新 中文 不切\n",
            "实际输入的参考文本: 那我们物联网概论总共分为三个章节，好，第一章首先要和大家介绍的是物联网的简介。\n",
            "实际输入的目标文本: 。大家好，歡迎來到這門課，人工智慧思維與創新\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Building prefix dict from the default dictionary ...\n",
            "DEBUG:jieba_fast:Building prefix dict from the default dictionary ...\n",
            "Dumping model to file cache /tmp/jieba.cache\n",
            "DEBUG:jieba_fast:Dumping model to file cache /tmp/jieba.cache\n",
            "Loading model cost 1.416 seconds.\n",
            "DEBUG:jieba_fast:Loading model cost 1.416 seconds.\n",
            "Prefix dict has been built succesfully.\n",
            "DEBUG:jieba_fast:Prefix dict has been built succesfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "实际输入的目标文本(切句后): 。大家好，歡迎來到這門課，人工智慧思維與創新\n",
            "实际输入的目标文本(每句): 。大家好，歡迎來到這門課，人工智慧思維與創新。\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|▊         | 118/1500 [00:02<00:28, 47.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T2S Decoding EOS [201 -> 319]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:660: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
            "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:874.)\n",
            "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.375\t1.562\t2.484\t1.480\n",
            "4.375\t1.562\t2.484\t1.480\n",
            "/content/drive/MyDrive/语音权重/20240329.wav_0000156800_0000395200.wav 那我们物联网概论总共分为三个章节，好，第一章首先要和大家介绍的是物联网的简介。 中文 我是張志勇老師，目前服務于淡江大學 中文 不切\n",
            "实际输入的参考文本: 那我们物联网概论总共分为三个章节，好，第一章首先要和大家介绍的是物联网的简介。\n",
            "实际输入的目标文本: 我是張志勇老師，目前服務于淡江大學\n",
            "实际输入的目标文本(切句后): 我是張志勇老師，目前服務于淡江大學\n",
            "实际输入的目标文本(每句): 我是張志勇老師，目前服務于淡江大學。\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 80/1500 [00:01<00:25, 55.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T2S Decoding EOS [201 -> 281]\n",
            "0.035\t0.052\t1.463\t0.578\n",
            "0.035\t0.052\t1.463\t0.578\n",
            "/content/drive/MyDrive/语音权重/20240329.wav_0000156800_0000395200.wav 那我们物联网概论总共分为三个章节，好，第一章首先要和大家介绍的是物联网的简介。 中文 這是我們人工智慧思維與創新的大綱 中文 不切\n",
            "实际输入的参考文本: 那我们物联网概论总共分为三个章节，好，第一章首先要和大家介绍的是物联网的简介。\n",
            "实际输入的目标文本: 這是我們人工智慧思維與創新的大綱\n",
            "实际输入的目标文本(切句后): 這是我們人工智慧思維與創新的大綱\n",
            "实际输入的目标文本(每句): 這是我們人工智慧思維與創新的大綱。\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 78/1500 [00:01<00:26, 54.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T2S Decoding EOS [201 -> 279]\n",
            "0.033\t0.060\t1.437\t0.847\n",
            "0.033\t0.060\t1.437\t0.847\n",
            "/content/drive/MyDrive/语音权重/20240329.wav_0000156800_0000395200.wav 那我们物联网概论总共分为三个章节，好，第一章首先要和大家介绍的是物联网的简介。 中文 首先，我會和大家分享一下什麼是人工智慧 中文 不切\n",
            "实际输入的参考文本: 那我们物联网概论总共分为三个章节，好，第一章首先要和大家介绍的是物联网的简介。\n",
            "实际输入的目标文本: 。首先，我會和大家分享一下什麼是人工智慧\n",
            "实际输入的目标文本(切句后): 。首先，我會和大家分享一下什麼是人工智慧\n",
            "实际输入的目标文本(每句): 。首先，我會和大家分享一下什麼是人工智慧。\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 87/1500 [00:01<00:25, 55.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T2S Decoding EOS [201 -> 288]\n",
            "0.034\t0.056\t1.587\t0.655\n",
            "0.034\t0.056\t1.587\t0.655\n",
            "合并后的音频已保存到：/content/Voice3/1/combine1.wav\n",
            "/content/drive/MyDrive/语音权重/20240329.wav_0000156800_0000395200.wav 那我们物联网概论总共分为三个章节，好，第一章首先要和大家介绍的是物联网的简介。 中文 緊接著呢，我會和大家分享一下人工智慧在實際生活中的一些應用 中文 不切\n",
            "实际输入的参考文本: 那我们物联网概论总共分为三个章节，好，第一章首先要和大家介绍的是物联网的简介。\n",
            "实际输入的目标文本: 緊接著呢，我會和大家分享一下人工智慧在實際生活中的一些應用\n",
            "实际输入的目标文本(切句后): 緊接著呢，我會和大家分享一下人工智慧在實際生活中的一些應用\n",
            "实际输入的目标文本(每句): 緊接著呢，我會和大家分享一下人工智慧在實際生活中的一些應用。\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  9%|▊         | 130/1500 [00:03<00:33, 41.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T2S Decoding EOS [201 -> 331]\n",
            "0.034\t0.083\t3.180\t0.462\n",
            "0.034\t0.083\t3.180\t0.462\n",
            "合并后的音频已保存到：/content/Voice3/2/combine2.wav\n",
            "/content/drive/MyDrive/语音权重/20240329.wav_0000156800_0000395200.wav 那我们物联网概论总共分为三个章节，好，第一章首先要和大家介绍的是物联网的简介。 中文 在最後呢，我會和大家分享一下我們這學期課程的一些大綱 中文 不切\n",
            "实际输入的参考文本: 那我们物联网概论总共分为三个章节，好，第一章首先要和大家介绍的是物联网的简介。\n",
            "实际输入的目标文本: 在最後呢，我會和大家分享一下我們這學期課程的一些大綱\n",
            "实际输入的目标文本(切句后): 在最後呢，我會和大家分享一下我們這學期課程的一些大綱\n",
            "实际输入的目标文本(每句): 在最後呢，我會和大家分享一下我們這學期課程的一些大綱。\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  9%|▉         | 133/1500 [00:02<00:24, 55.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T2S Decoding EOS [201 -> 334]\n",
            "0.034\t0.056\t2.391\t0.466\n",
            "0.034\t0.056\t2.391\t0.466\n",
            "合并后的音频已保存到：/content/Voice3/3/combine3.wav\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hProcessing with background: /content/幻灯片1.PNG\n",
            "Video 1 processing complete and saved to /content/combined1/1.mp4\n",
            "Processing with background: /content/幻灯片2.PNG\n",
            "Video 2 processing complete and saved to /content/combined1/2.mp4\n",
            "Processing with background: /content/幻灯片3.PNG\n",
            "Video 3 processing complete and saved to /content/combined1/3.mp4\n",
            "All processing complete.\n",
            "Moviepy - Building video /content/extended/combine3.mp4.\n",
            "Moviepy - Writing video /content/extended/combine3.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready /content/extended/combine3.mp4\n",
            "Extended video saved to /content/extended/combine3.mp4\n",
            "Moviepy - Building video /content/extended/combine2.mp4.\n",
            "Moviepy - Writing video /content/extended/combine2.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready /content/extended/combine2.mp4\n",
            "Extended video saved to /content/extended/combine2.mp4\n",
            "Moviepy - Building video /content/extended/combine1.mp4.\n",
            "Moviepy - Writing video /content/extended/combine1.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready /content/extended/combine1.mp4\n",
            "Extended video saved to /content/extended/combine1.mp4\n",
            "Moved '/content/Voice3/1/combine1.wav' to '/content/extended/combine1.wav'\n",
            "Moved '/content/Voice3/2/combine2.wav' to '/content/extended/combine2.wav'\n",
            "Moved '/content/Voice3/3/combine3.wav' to '/content/extended/combine3.wav'\n",
            "Inference completed for combine3. Result saved to /content/final_result/combine3_result.mp4\n",
            "Inference completed for combine1. Result saved to /content/final_result/combine1_result.mp4\n",
            "Inference completed for combine2. Result saved to /content/final_result/combine2_result.mp4\n",
            "Moviepy - Building video /content/final_combined_video.mp4.\n",
            "MoviePy - Writing audio in final_combined_videoTEMP_MPY_wvf_snd.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video /content/final_combined_video.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "t:  58%|█████▊    | 469/806 [00:38<00:37,  9.10it/s, now=None]WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/moviepy/video/io/ffmpeg_reader.py:123: UserWarning: Warning: in file /content/final_result/combine1_result.mp4, 6220800 bytes wanted but 0 bytes read,at frame 468/472, at time 15.60/15.72 sec. Using the last valid frame instead.\n",
            "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
            "\n",
            "t:  58%|█████▊    | 470/806 [00:38<00:37,  8.99it/s, now=None]WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/moviepy/video/io/ffmpeg_reader.py:123: UserWarning: Warning: in file /content/final_result/combine1_result.mp4, 6220800 bytes wanted but 0 bytes read,at frame 469/472, at time 15.63/15.72 sec. Using the last valid frame instead.\n",
            "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/moviepy/video/io/ffmpeg_reader.py:123: UserWarning: Warning: in file /content/final_result/combine1_result.mp4, 6220800 bytes wanted but 0 bytes read,at frame 470/472, at time 15.67/15.72 sec. Using the last valid frame instead.\n",
            "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
            "\n",
            "t:  59%|█████▊    | 472/806 [00:38<00:34,  9.76it/s, now=None]WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/moviepy/video/io/ffmpeg_reader.py:123: UserWarning: Warning: in file /content/final_result/combine1_result.mp4, 6220800 bytes wanted but 0 bytes read,at frame 471/472, at time 15.70/15.72 sec. Using the last valid frame instead.\n",
            "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
            "\n",
            "t:  79%|███████▊  | 633/806 [00:50<00:12, 14.28it/s, now=None]WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/moviepy/video/io/ffmpeg_reader.py:123: UserWarning: Warning: in file /content/final_result/combine2_result.mp4, 6220800 bytes wanted but 0 bytes read,at frame 161/166, at time 5.37/5.50 sec. Using the last valid frame instead.\n",
            "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
            "\n",
            "t:  79%|███████▉  | 635/806 [00:50<00:11, 14.47it/s, now=None]WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/moviepy/video/io/ffmpeg_reader.py:123: UserWarning: Warning: in file /content/final_result/combine2_result.mp4, 6220800 bytes wanted but 0 bytes read,at frame 162/166, at time 5.40/5.50 sec. Using the last valid frame instead.\n",
            "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/moviepy/video/io/ffmpeg_reader.py:123: UserWarning: Warning: in file /content/final_result/combine2_result.mp4, 6220800 bytes wanted but 0 bytes read,at frame 163/166, at time 5.43/5.50 sec. Using the last valid frame instead.\n",
            "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
            "\n",
            "t:  79%|███████▉  | 637/806 [00:50<00:10, 15.65it/s, now=None]WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/moviepy/video/io/ffmpeg_reader.py:123: UserWarning: Warning: in file /content/final_result/combine2_result.mp4, 6220800 bytes wanted but 0 bytes read,at frame 164/166, at time 5.47/5.50 sec. Using the last valid frame instead.\n",
            "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
            "\n",
            "t: 100%|█████████▉| 803/806 [01:04<00:00, 14.82it/s, now=None]WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/moviepy/video/io/ffmpeg_reader.py:123: UserWarning: Warning: in file /content/final_result/combine3_result.mp4, 6220800 bytes wanted but 0 bytes read,at frame 165/169, at time 5.50/5.62 sec. Using the last valid frame instead.\n",
            "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/moviepy/video/io/ffmpeg_reader.py:123: UserWarning: Warning: in file /content/final_result/combine3_result.mp4, 6220800 bytes wanted but 0 bytes read,at frame 166/169, at time 5.53/5.62 sec. Using the last valid frame instead.\n",
            "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
            "\n",
            "t: 100%|█████████▉| 805/806 [01:04<00:00, 13.80it/s, now=None]WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/moviepy/video/io/ffmpeg_reader.py:123: UserWarning: Warning: in file /content/final_result/combine3_result.mp4, 6220800 bytes wanted but 0 bytes read,at frame 167/169, at time 5.57/5.62 sec. Using the last valid frame instead.\n",
            "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/moviepy/video/io/ffmpeg_reader.py:123: UserWarning: Warning: in file /content/final_result/combine3_result.mp4, 6220800 bytes wanted but 0 bytes read,at frame 168/169, at time 5.60/5.62 sec. Using the last valid frame instead.\n",
            "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready /content/final_combined_video.mp4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e105d4ab-7de0-419b-a152-f15032ceb7c8\", \"final_combined_video.mp4\", 1980721)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install python-docx\n",
        "!rm -rf /content/sample_data\n",
        "!mkdir /content/sample_data\n",
        "!git clone https://github.com/zabique/Wav2Lip\n",
        "!wget 'https://iiitaphyd-my.sharepoint.com/personal/radrabha_m_research_iiit_ac_in/_layouts/15/download.aspx?share=EdjI7bZlgApMqsVoEUUXpLsBxqXbn5z8VTmoxp55YNDcIA' -O '/content/Wav2Lip/checkpoints/wav2lip_gan.pth'\n",
        "a = !pip install https://raw.githubusercontent.com/AwaleSajil/ghc/master/ghc-1.0-py3-none-any.whl\n",
        "!cd Wav2Lip && pip install -r requirements.txt\n",
        "!wget \"https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\" -O \"/content/Wav2Lip/face_detection/detection/sfd/s3fd.pth\"\n",
        "!pip install -q youtube-dl\n",
        "!pip install ffmpeg-python\n",
        "!pip install librosa==0.9.1\n",
        "\n",
        "#this code for recording audio\n",
        "\"\"\"\n",
        "To write this piece of code I took inspiration/code from a lot of places.\n",
        "It was late night, so I'm not sure how much I created or just copied o.O\n",
        "Here are some of the possible references:\n",
        "https://blog.addpipe.com/recording-audio-in-the-browser-using-pure-html5-and-minimal-javascript/\n",
        "https://stackoverflow.com/a/18650249\n",
        "https://hacks.mozilla.org/2014/06/easy-audio-capture-with-the-mediarecorder-api/\n",
        "https://air.ghost.io/recording-to-an-audio-file-using-html5-and-js/\n",
        "https://stackoverflow.com/a/49019356\n",
        "\"\"\"\n",
        "from IPython.display import HTML, Audio\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import numpy as np\n",
        "from scipy.io.wavfile import read as wav_read\n",
        "import io\n",
        "import ffmpeg\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "print(\"\\nDone\")\n",
        "from docx import Document\n",
        "! pip install python-pptx\n",
        "!nvidia-smi\n",
        "!git clone https://github.com/Kedreamix/Linly-Talker\n",
        "%cd /content/Linly-Talker/\n",
        "!pip install -r VITS/requirements_gptsovits.txt\n",
        "!pip install gradio\n",
        "!rm -rf Linly-Talker/\n",
        "!git lfs install\n",
        "!git clone https://huggingface.co/Kedreamix/Linly-Talker\n",
        "%cd /content/Linly-Talker/\n",
        "!mkdir checkpoints\n",
        "%mv Linly-Talker/checkpoints/* ./checkpoints/\n",
        "%mv Linly-Talker/GPT_SoVITS/pretrained_models/* ./GPT_SoVITS/pretrained_models/\n",
        "%mv Linly-Talker/Qwen ./\n",
        "import sys\n",
        "print(sys.path)\n",
        "! pip install -r /content/Linly-Talker/VITS/requirements_xtts.txt\n",
        "\n",
        "\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "from docx import Document\n",
        "from pydub import AudioSegment\n",
        "from VITS.GPT_SoVITS import GPT_SoVITS\n",
        "\n",
        "# 初始化和配置文件夹\n",
        "source_dir = '/content'\n",
        "target_dir = '/content/doc_folder'\n",
        "audio_base_dir = '/content/Voice3'\n",
        "\n",
        "if not os.path.exists(target_dir):\n",
        "    os.makedirs(target_dir)\n",
        "\n",
        "# 移动文档到目标文件夹\n",
        "for file in os.listdir(source_dir):\n",
        "    if file.endswith('.docx') and any(char.isdigit() for char in file):\n",
        "        src_path = os.path.join(source_dir, file)\n",
        "        dst_path = os.path.join(target_dir, file)\n",
        "        shutil.move(src_path, dst_path)\n",
        "        print(f'文件 {file} 已移动到 {target_dir}')\n",
        "\n",
        "vits = GPT_SoVITS()\n",
        "gpt_path = \"/content/drive/MyDrive/语音权重/testzhang-e50.ckpt\"\n",
        "sovits_path = \"/content/drive/MyDrive/语音权重/testzhang_e8_s128.pth\"\n",
        "vits.load_model(gpt_path, sovits_path)\n",
        "\n",
        "ref_wav_path = \"/content/drive/MyDrive/语音权重/20240329.wav_0000156800_0000395200.wav\"\n",
        "prompt_text = \"那我们物联网概论总共分为三个章节，好，第一章首先要和大家介绍的是物联网的简介。\"\n",
        "prompt_language = \"中文\"\n",
        "\n",
        "def process_docs(folder_path):\n",
        "    doc_files = [file for file in os.listdir(folder_path) if file.endswith('.docx')]\n",
        "    doc_files.sort(key=lambda x: int(re.search(r'\\d+', x).group()))\n",
        "\n",
        "    for doc_file in doc_files:\n",
        "        doc_id = re.search(r'\\d+', doc_file).group()\n",
        "        audio_save_dir = os.path.join(audio_base_dir, doc_id)\n",
        "        os.makedirs(audio_save_dir, exist_ok=True)\n",
        "\n",
        "        file_path = os.path.join(folder_path, doc_file)\n",
        "        process_docx(file_path, audio_save_dir, doc_id)\n",
        "\n",
        "def process_docx(file_path, audio_save_dir, doc_id):\n",
        "    doc = Document(file_path)\n",
        "    sentence_id = 0\n",
        "    combined = AudioSegment.empty()\n",
        "\n",
        "    for para in doc.paragraphs:\n",
        "        sentences = re.split(r'[。？?]', para.text)\n",
        "        for sentence in sentences:\n",
        "            if sentence.strip():\n",
        "                save_path = os.path.join(audio_save_dir, f'{sentence_id}.wav')\n",
        "                vits.predict(ref_wav_path=ref_wav_path,\n",
        "                             prompt_text=prompt_text,\n",
        "                             prompt_language=prompt_language,\n",
        "                             text=sentence.strip(),\n",
        "                             text_language=\"中文\",\n",
        "                             how_to_cut=\"不切\",\n",
        "                             save_path=save_path)\n",
        "                sound = AudioSegment.from_file(save_path)\n",
        "                combined += sound\n",
        "                sentence_id += 1\n",
        "\n",
        "    output_path = os.path.join(audio_save_dir, f'combine{doc_id}.wav')\n",
        "    combined.export(output_path, format='wav')\n",
        "    print(f'合并后的音频已保存到：{output_path}')\n",
        "\n",
        "process_docs(target_dir)\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "!pip install -q mediapipe opencv-python pydub\n",
        "import os\n",
        "os.environ['PYTHONUTF8'] = '1'\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "import os\n",
        "from glob import glob\n",
        "\n",
        "# 初始化 Selfie Segmentation\n",
        "mp_selfie_segmentation = mp.solutions.selfie_segmentation\n",
        "selfie_segmentation = mp_selfie_segmentation.SelfieSegmentation(model_selection=1)\n",
        "\n",
        "# 设定基础视频路径和输出文件夹路径\n",
        "base_video_path = \"/content/basevideo.mp4\"\n",
        "output_folder = \"/content/combined1\"\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "# 获取所有背景图像路径\n",
        "background_images = sorted(glob(\"/content/*.PNG\"), key=lambda x: int(os.path.splitext(os.path.basename(x))[0].split('幻灯片')[1]))\n",
        "\n",
        "# 处理每一个背景图像\n",
        "for idx, background_image_path in enumerate(background_images):\n",
        "    print(f\"Processing with background: {background_image_path}\")\n",
        "\n",
        "    # 设置输出视频路径\n",
        "    output_video_path = os.path.join(output_folder, f\"{idx+1}.mp4\")\n",
        "\n",
        "    # 读取背景图像\n",
        "    background_original = cv2.imread(background_image_path)\n",
        "    if background_original is None:\n",
        "        print(\"Error: Background image could not be read.\")\n",
        "        continue\n",
        "\n",
        "    # 读取视频文件\n",
        "    cap = cv2.VideoCapture(base_video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(\"Error: Could not open video.\")\n",
        "        continue\n",
        "\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    # 调整背景图像大小\n",
        "    scale = min(width / background_original.shape[1], height / background_original.shape[0])\n",
        "    new_width = int(background_original.shape[1] * scale)\n",
        "    new_height = int(background_original.shape[0] * scale)\n",
        "    background_resized = cv2.resize(background_original, (new_width, new_height))\n",
        "\n",
        "    # 创建视频帧相同大小的背景\n",
        "    background = np.zeros((height, width, 3), dtype=np.uint8)\n",
        "    start_x = (width - new_width) // 2\n",
        "    start_y = (height - new_height) // 2\n",
        "    background[start_y:start_y+new_height, start_x:start_x+new_width] = background_resized\n",
        "\n",
        "    # 初始化视频写入器\n",
        "    out = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
        "\n",
        "    # 设置人物缩放比例和位置\n",
        "    scale_factor = 0.56\n",
        "    person_width = int(width * scale_factor)\n",
        "    person_height = int(height * scale_factor)\n",
        "    person_x = width - person_width\n",
        "    person_y = height - person_height\n",
        "\n",
        "    # 视频处理\n",
        "    try:\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            # 应用自拍分割\n",
        "            results = selfie_segmentation.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "            condition = np.stack((results.segmentation_mask,) * 3, axis=-1) > 0.5\n",
        "\n",
        "            # 提取人物并调整大小\n",
        "            person = np.where(condition, frame, np.zeros_like(frame))\n",
        "            person_small = cv2.resize(person, (person_width, person_height))\n",
        "            person_mask_small = cv2.resize(condition.astype(np.uint8), (person_width, person_height))\n",
        "\n",
        "            # 合成人物到背景\n",
        "            new_background = background.copy()\n",
        "            for i in range(person_height):\n",
        "                for j in range(person_width):\n",
        "                    if person_mask_small[i, j, 0]:\n",
        "                        new_background[person_y+i, person_x+j] = person_small[i, j]\n",
        "\n",
        "            out.write(new_background)\n",
        "\n",
        "    finally:\n",
        "        cap.release()\n",
        "        out.release()\n",
        "        print(f\"Video {idx+1} processing complete and saved to {output_video_path}\")\n",
        "\n",
        "# 结束 Selfie Segmentation\n",
        "selfie_segmentation.close()\n",
        "print(\"All processing complete.\")\n",
        "import os\n",
        "from moviepy.editor import VideoFileClip, concatenate_videoclips\n",
        "from pydub import AudioSegment\n",
        "\n",
        "def extend_video_to_audio_length(video_path, audio_path, output_path):\n",
        "    video_clip = VideoFileClip(video_path)\n",
        "    audio = AudioSegment.from_file(audio_path)\n",
        "    audio_duration = len(audio) / 1000.0  # 获取音频长度（秒）\n",
        "\n",
        "    repeat_count = int(audio_duration // video_clip.duration)  # 计算需要重复视频的次数\n",
        "    last_clip_duration = audio_duration % video_clip.duration  # 最后一段视频的长度\n",
        "\n",
        "    clips = [video_clip] * repeat_count\n",
        "    if last_clip_duration > 0:\n",
        "        last_clip = video_clip.subclip(0, last_clip_duration)\n",
        "        clips.append(last_clip)\n",
        "\n",
        "    final_clip = concatenate_videoclips(clips)\n",
        "    final_clip.write_videofile(output_path, codec='libx264')  # 输出视频文件\n",
        "\n",
        "def process_videos_and_audios(video_folder, audio_base_folder, output_folder):\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    video_files = [f for f in os.listdir(video_folder) if f.endswith('.mp4')]\n",
        "\n",
        "    for video_file in video_files:\n",
        "        video_index = video_file.split('.')[0].replace('video', '')  # 从视频文件名中提取编号\n",
        "        audio_folder = os.path.join(audio_base_folder, video_index)  # 根据编号找到对应的子文件夹\n",
        "\n",
        "        if os.path.exists(audio_folder):\n",
        "            audio_files = [f for f in os.listdir(audio_folder) if 'combine' in f and f.endswith('.wav')]\n",
        "            if audio_files:\n",
        "                video_path = os.path.join(video_folder, video_file)\n",
        "                audio_path = os.path.join(audio_folder, audio_files[0])\n",
        "                output_video_path = os.path.join(output_folder, f'combine{video_index}.mp4')\n",
        "                extend_video_to_audio_length(video_path, audio_path, output_video_path)\n",
        "                print(f\"Extended video saved to {output_video_path}\")\n",
        "            else:\n",
        "                print(f\"No 'combine' audio files found in folder {audio_folder} for video {video_file}\")\n",
        "        else:\n",
        "            print(f\"Audio folder {audio_folder} does not exist for video {video_file}\")\n",
        "\n",
        "process_videos_and_audios('/content/combined1', '/content/Voice3', '/content/extended')\n",
        "import shutil\n",
        "\n",
        "def move_specific_wav_files(source_dir, target_dir):\n",
        "    # 确保目标目录存在，如果不存在则创建\n",
        "    if not os.path.exists(target_dir):\n",
        "        os.makedirs(target_dir)\n",
        "\n",
        "    # 遍历源目录中的所有子目录\n",
        "    for subdir, dirs, files in os.walk(source_dir):\n",
        "        for file in files:\n",
        "            if file.endswith('.wav') and 'combine' in file:\n",
        "                # 构建源文件和目标文件的完整路径\n",
        "                source_file = os.path.join(subdir, file)\n",
        "                target_file = os.path.join(target_dir, file)\n",
        "\n",
        "                # 移动文件\n",
        "                shutil.move(source_file, target_file)\n",
        "                print(f\"Moved '{source_file}' to '{target_file}'\")\n",
        "\n",
        "# 指定源目录和目标目录\n",
        "source_directory = '/content/Voice3'\n",
        "target_directory = '/content/extended'\n",
        "\n",
        "# 调用函数\n",
        "move_specific_wav_files(source_directory, target_directory)\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "import shutil\n",
        "\n",
        "os.chdir('/content/Wav2Lip')\n",
        "def run_inference_on_pairs(face_audio_dir, output_dir, checkpoint_path):\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    files = os.listdir(face_audio_dir)\n",
        "    prefixes = set([os.path.splitext(file)[0] for file in files if file.startswith('combine')])\n",
        "\n",
        "    for prefix in prefixes:\n",
        "        face_path = os.path.join(face_audio_dir, f\"{prefix}.mp4\")\n",
        "        audio_path = os.path.join(face_audio_dir, f\"{prefix}.wav\")\n",
        "\n",
        "        if os.path.exists(face_path) and os.path.exists(audio_path):\n",
        "            output_path = os.path.join(output_dir, f\"{prefix}_result.mp4\")\n",
        "\n",
        "            command = [\n",
        "                'python', '/content/Wav2Lip/inference.py',\n",
        "                '--checkpoint_path', checkpoint_path,\n",
        "                '--face', face_path,\n",
        "                '--audio', audio_path,\n",
        "                '--outfile', output_path\n",
        "            ]\n",
        "            subprocess.run(command, check=True)\n",
        "            print(f\"Inference completed for {prefix}. Result saved to {output_path}\")\n",
        "\n",
        "face_audio_directory = '/content/extended'\n",
        "final_output_directory = '/content/final_result'\n",
        "checkpoint_path = '/content/Wav2Lip/checkpoints/wav2lip_gan.pth'\n",
        "\n",
        "run_inference_on_pairs(face_audio_directory, final_output_directory, checkpoint_path)\n",
        "from moviepy.editor import VideoFileClip, concatenate_videoclips\n",
        "import os\n",
        "\n",
        "def sort_and_concatenate_videos(directory, output_path):\n",
        "    # 获取所有的视频文件\n",
        "    files = [file for file in os.listdir(directory) if file.endswith('.mp4')]\n",
        "    # 按照文件名中的数字进行排序\n",
        "    files.sort(key=lambda x: int(x.split('_')[0].replace('combine', '')))\n",
        "\n",
        "    # 加载视频文件为 VideoFileClip 对象\n",
        "    clips = [VideoFileClip(os.path.join(directory, file)) for file in files]\n",
        "\n",
        "    # 使用 concatenate_videoclips 合并视频\n",
        "    final_clip = concatenate_videoclips(clips, method='compose')\n",
        "\n",
        "    # 写出最终的视频文件\n",
        "    final_clip.write_videofile(output_path, codec='libx264')\n",
        "\n",
        "# 指定目录和输出视频文件的路径\n",
        "source_directory = '/content/final_result'\n",
        "final_video_path = '/content/final_combined_video.mp4'\n",
        "\n",
        "# 调用函数\n",
        "sort_and_concatenate_videos(source_directory, final_video_path)\n",
        "from google.colab import files\n",
        "files.download('/content/final_combined_video.mp4')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}